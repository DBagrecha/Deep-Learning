{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image_captions.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyPZYyFV45rBSiNQVLeJEjlz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DBagrecha/Deep-Learning/blob/main/Image_captions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLU8WavJEY__"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import string\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "from time import time\n",
        "\n",
        "from keras import Input, layers\n",
        "from keras import optimizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import LSTM, Embedding, Dense, Activation, Flatten, Reshape, Dropout\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.layers.merge import add\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "FUWdBkE7j6Xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/flickr30k_images/results.csv\",sep = '|')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "gP0Ncx6mub4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename({' comment_number': 'comment_number', ' comment': 'comment'}, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "Pzh_J7wj4LG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "G9b6XIwW7S-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df['image_name']=='1514957266.jpg']['comment_number']"
      ],
      "metadata": {
        "id": "hQs2L_F-80iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['comment_number']=list(map(lambda x : (x[1:]),df['comment_number']))"
      ],
      "metadata": {
        "id": "yp_rd9pc66xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['comment']=list(map(lambda x : str(x)[1:],df['comment']))"
      ],
      "metadata": {
        "id": "q2b3Yba-7CX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "impath='/content/drive/MyDrive/flickr30k_images/images/'\n",
        "x=plt.imread(impath+'85600252.jpg')\n",
        "plt.imshow(x)\n",
        "plt.show()\n",
        "print(df.loc[df['image_name']=='1000092795.jpg']['comment'])"
      ],
      "metadata": {
        "id": "ksOs8aBuvU_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab=set()\n",
        "for i in df['comment']:\n",
        "  vocab.update(i.split(' '))\n",
        "print(len(vocab))"
      ],
      "metadata": {
        "id": "OlPRnAOO2MQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['image_path']=list(map(lambda x : impath+x,df['image_name']))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "yaeg-D2J_Nz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(columns=['comment_number'])"
      ],
      "metadata": {
        "id": "x5pJCivmsA7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "BjuqlR8Is3Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images=df['image_name'].unique()[:1500]\n",
        "images"
      ],
      "metadata": {
        "id": "tOBO03KNFbQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MupftLgxHJkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['image_path'], df['comment'], test_size=0.25)"
      ],
      "metadata": {
        "id": "BursQO0dtHtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repeat=10\n",
        "w=dict()\n",
        "for i in y_train:\n",
        "  for j in i.split(\" \"):\n",
        "    if j in w.keys():\n",
        "      w[j]+=1\n",
        "    else:\n",
        "      w[j]=1\n",
        "new_vocab=[word for word in w.keys() if (w[word]>=repeat)]"
      ],
      "metadata": {
        "id": "QYmjQdhVuIJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(new_vocab)"
      ],
      "metadata": {
        "id": "TB0iM0fIvoHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indtoword = {}\n",
        "wordtoind = {}\n",
        "ind = 1\n",
        "for w in new_vocab:\n",
        "    wordtoind[w] = ind\n",
        "    indtoword[ind] = w\n",
        "    ind += 1\n",
        "\n",
        "vocab_size = len(indtoword) + 1"
      ],
      "metadata": {
        "id": "dgz1uROXw2kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "id": "WaF9ROON3gy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length=max([len(i.split(\" \")) for i in df['comment']])  "
      ],
      "metadata": {
        "id": "FZUtVzle3lbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_path='/content/drive/MyDrive/flickr30k_images/'\n",
        "embeddings_index = {} \n",
        "f = open(os.path.join(glove_path, 'glove.6B.200d.txt'), encoding=\"utf-8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs"
      ],
      "metadata": {
        "id": "7j8ZSHQ29bQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 200\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in wordtoind.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "SqN-0mmIB3VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = InceptionV3(weights='imagenet')"
      ],
      "metadata": {
        "id": "o6_-DZ7-C2hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_new = Model(model.input, model.layers[-2].output)"
      ],
      "metadata": {
        "id": "8GDLHsAKC-Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(image_path):\n",
        "    img = image.load_img(image_path, target_size=(299, 299))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "h-NY34L3DDxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(image):\n",
        "    image = preprocess(image) \n",
        "    fea_vec = model_new.predict(image) \n",
        "    fea_vec = np.reshape(fea_vec, fea_vec.shape[1])\n",
        "    return fea_vec"
      ],
      "metadata": {
        "id": "CshIHEgaDW5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_train = {}\n",
        "for img in images:\n",
        "    encoding_train[img] = encode(impath+img)\n",
        "train_features = encoding_train"
      ],
      "metadata": {
        "id": "7ZAlzm3uEIZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_im=df['image_name'].unique()[-500:]"
      ],
      "metadata": {
        "id": "lIM_hXDiG_sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_test = {}\n",
        "for img in test_im:\n",
        "    encoding_test[img] = encode(impath+img)\n",
        "test_features = encoding_test"
      ],
      "metadata": {
        "id": "Dz67jDVwahpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs1 = Input(shape=(2048,))\n",
        "fe1 = Dropout(0.5)(inputs1)\n",
        "fe2 = Dense(256, activation='relu')(fe1)\n",
        "\n",
        "inputs2 = Input(shape=(max_length,))\n",
        "se1 = Embedding(vocab_size, embedding_dim, mask_zero=True)(inputs2)\n",
        "se2 = Dropout(0.5)(se1)\n",
        "se3 = LSTM(256)(se2)\n",
        "\n",
        "decoder1 = add([fe2, se3])\n",
        "decoder2 = Dense(256, activation='relu')(decoder1)\n",
        "outputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
        "\n",
        "model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "zpnYjI4jCTwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[2].set_weights([embedding_matrix])\n",
        "model.layers[2].trainable = False"
      ],
      "metadata": {
        "id": "y7tKYIqlazvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "CFzNeQD6Q10R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['comment']=list(map(lambda x: 'start '+x+' end',df['comment']))"
      ],
      "metadata": {
        "id": "wJxg_zSDS6_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gNGu9t3JU_wC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_desc={}\n",
        "for i in images:\n",
        "  train_desc[i]=list(df.loc[df['image_name']==i]['comment'])"
      ],
      "metadata": {
        "id": "HEoIE_nrQ4gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator(descriptions, photos, wordtoind, max_length, num_photos_per_batch):\n",
        "    X1, X2, y = list(), list(), list()\n",
        "    n=0\n",
        "    while 1:\n",
        "        for key, desc_list in descriptions.items():\n",
        "            n+=1\n",
        "            photo=photos[key]\n",
        "            for desc in desc_list:\n",
        "                \n",
        "                seq = [wordtoind[word] for word in desc.split(' ') if word in wordtoind]\n",
        "                \n",
        "                for i in range(1, len(seq)):\n",
        "                    \n",
        "                    in_seq, out_seq = seq[:i], seq[i]\n",
        "                    \n",
        "                    in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n",
        "                    \n",
        "                    out_seq = to_categorical([out_seq], num_classes=vocab_size)[0]\n",
        "                    \n",
        "                    X1.append(photo)\n",
        "                    X2.append(in_seq)\n",
        "                    y.append(out_seq)\n",
        "\n",
        "            if n==num_photos_per_batch:\n",
        "                yield ([np.array(X1), np.array(X2)], np.array(y))\n",
        "                X1, X2, y = list(), list(), list()\n",
        "                n=0"
      ],
      "metadata": {
        "id": "GFxlBuHiTb44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 60\n",
        "batch_size = 50\n",
        "steps = len(train_desc)//batch_size\n",
        "\n",
        "generator = data_generator(train_desc, train_features, wordtoind, max_length, batch_size)\n",
        "model.fit(generator, epochs=epochs, steps_per_epoch=steps, verbose=1)"
      ],
      "metadata": {
        "id": "16iWm7bTWWsF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(generator, epochs=5, steps_per_epoch=steps, verbose=1)"
      ],
      "metadata": {
        "id": "uR3-EKtgAPv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greedySearch(photo):\n",
        "    in_text = 'start'\n",
        "    for i in range(max_length):\n",
        "        sequence = [wordtoind[w] for w in in_text.split() if w in wordtoind]\n",
        "        sequence = pad_sequences([sequence], maxlen=max_length)\n",
        "        yhat = model.predict([photo,sequence], verbose=0)\n",
        "        yhat = np.argmax(yhat)\n",
        "        word = indtoword[yhat]\n",
        "        in_text += ' ' + word\n",
        "        if word == 'end':\n",
        "            break\n",
        "\n",
        "    final = in_text.split()\n",
        "    final = final[1:-1]\n",
        "    final = ' '.join(final)\n",
        "    return final"
      ],
      "metadata": {
        "id": "HhfFh_7LsM1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def beam_search_predictions(image, beam_index = 3):\n",
        "    start = [wordtoind[\"start\"]]\n",
        "    start_word = [[start, 0.0]]\n",
        "    while len(start_word[0][0]) < max_length:\n",
        "        temp = []\n",
        "        for s in start_word:\n",
        "            par_caps = sequence.pad_sequences([s[0]], maxlen=max_length, padding='post')\n",
        "            preds = model.predict([image,par_caps], verbose=0)\n",
        "            word_preds = np.argsort(preds[0])[-beam_index:]\n",
        "            # Getting the top <beam_index>(n) predictions and creating a \n",
        "            # new list so as to put them via the model again\n",
        "            for w in word_preds:\n",
        "                next_cap, prob = s[0][:], s[1]\n",
        "                next_cap.append(w)\n",
        "                prob += preds[0][w]\n",
        "                temp.append([next_cap, prob])\n",
        "                    \n",
        "        start_word = temp\n",
        "        # Sorting according to the probabilities\n",
        "        start_word = sorted(start_word, reverse=False, key=lambda l: l[1])\n",
        "        # Getting the top words\n",
        "        start_word = start_word[-beam_index:]\n",
        "    \n",
        "    start_word = start_word[-1][0]\n",
        "    intermediate_caption = [indtoword[i] for i in start_word]\n",
        "    final_caption = []\n",
        "    \n",
        "    for i in intermediate_caption:\n",
        "        if i != 'end':\n",
        "            final_caption.append(i)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    final_caption = ' '.join(final_caption[1:])\n",
        "    return final_caption"
      ],
      "metadata": {
        "id": "tE2EpsTeW0L6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pic = '900144365.jpg'\n",
        "image = encoding_test[pic].reshape((1,2048))\n",
        "x=plt.imread(impath+pic)\n",
        "plt.imshow(x)\n",
        "plt.show()\n",
        "\n",
        "print(\"Greedy Search:\",greedySearch(image))\n",
        "print(\"Beam Search, K = 3:\",beam_search_predictions(image, beam_index = 3))\n",
        "print(\"Beam Search, K = 5:\",beam_search_predictions(image, beam_index = 5))\n",
        "print(\"Beam Search, K = 7:\",beam_search_predictions(image, beam_index = 7))\n",
        "print(\"Beam Search, K = 10:\",beam_search_predictions(image, beam_index = 10))"
      ],
      "metadata": {
        "id": "mUKC_JWbsEH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bsO-cb6X-pnU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}